{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representations: Words to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def get_data(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        dirname = os.path.dirname(filename)\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "    urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "get_data(embedding_url, 'data/glove.6B.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip data/glove.6B.zip \n",
    "!mv glove.6B.300d.txt data/glove.6B.300d.txt \n",
    "!mv glove.6B.200d.txt data/glove.6B.200d.txt \n",
    "!mv glove.6B.100d.txt data/glove.6B.100d.txt \n",
    "!mv glove.6B.50d.txt data/glove.6B.50d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pretrained embeddings\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'data/glove.6B.300d.txt'\n",
    "\n",
    "word2vec_output_file = 'data/glove.6B.300d.word2vec.txt'\n",
    "\n",
    "if not os.path.exists(word2vec_output_file):\n",
    "    glove2word2vec(glove_input_file,word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "filename = word2vec_output_file\n",
    "\n",
    "pretrained_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.6713277101516724)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Using the (king - man) + woman example\n",
    "result = pretrained_model.wv.most_similar(positive = ['woman','king'], negative=['man'], topn=1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('indian', 0.7355823516845703),\n",
       " ('pakistan', 0.7285579442977905),\n",
       " ('delhi', 0.6846907138824463),\n",
       " ('bangladesh', 0.6203191876411438),\n",
       " ('lanka', 0.609517514705658),\n",
       " ('sri', 0.6011613607406616),\n",
       " ('kashmir', 0.5746493935585022),\n",
       " ('nepal', 0.5421023368835449),\n",
       " ('pradesh', 0.5405811071395874),\n",
       " ('maharashtra', 0.518537700176239)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.wv.most_similar('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling OOV words\n",
    "#Using the TED dataset to compare Fasttext and Word2vec\n",
    "\n",
    "ted_dataset = \"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\"\n",
    "get_data(ted_dataset,\"data/ted_en.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import lxml.etree\n",
    "with zipfile.ZipFile('data/ted_en.zip','r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml','r'))\n",
    "input_text = '\\n'.join(doc.xpath('//content/text()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit. I'm actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. A\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove parenthesis\n",
    "import re\n",
    "# remove parenthesis \n",
    "input_text_noparens = re.sub(r'\\([^)]*\\)', '', input_text)\n",
    "\n",
    "# store as list of sentences\n",
    "sentences_strings_ted = []\n",
    "for line in input_text_noparens.split('\\n'):\n",
    "    m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
    "    sentences_strings_ted.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
    "\n",
    "# store as list of lists of words\n",
    "sentences_ted = []\n",
    "for sent_str in sentences_strings_ted:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "    sentences_ted.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_ted[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "fasttext_ted_model = FastText(sentences_ted, size=100,window=5, min_count=5, workers=-1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indians', 0.5911639928817749),\n",
       " ('indian', 0.5406097769737244),\n",
       " ('indiana', 0.4898717999458313),\n",
       " ('indicated', 0.4400438070297241),\n",
       " ('indicate', 0.4042605757713318),\n",
       " ('internal', 0.39166826009750366),\n",
       " ('interior', 0.3871103823184967),\n",
       " ('byproducts', 0.3752930164337158),\n",
       " ('princesses', 0.37265270948410034),\n",
       " ('indications', 0.369659960269928)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_ted_model.wv.most_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "word2vec_ted_model = Word2Vec(sentences=sentences_ted, size=100, window=5, min_count=5, workers=-1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crooked', 0.4316353499889374),\n",
       " ('neurosurgeon', 0.4018043875694275),\n",
       " ('compartment', 0.38469767570495605),\n",
       " ('band', 0.3766378164291382),\n",
       " ('torajans', 0.34789350628852844),\n",
       " ('chassis', 0.3418603539466858),\n",
       " ('district', 0.3298587501049042),\n",
       " ('split', 0.3265147805213928),\n",
       " ('misinterpreted', 0.32462072372436523),\n",
       " ('documenting', 0.32307395339012146)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_ted_model.wv.most_similar(\"india\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
